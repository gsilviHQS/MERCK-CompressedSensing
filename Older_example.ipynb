{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First tests on Compressed Sensing\n",
    "The aim of this notebook is to demonstrate the use of compressed sensing.\n",
    "Tutorial from http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/\n",
    "\n",
    "# Scope\n",
    "\"Compressed sensing\" refers to a technique that can be used to reconstruct a signal from a smaller number of samples than would be required using traditional methods. This technique is particularly well suited to signals that are known to be sparse in the frequency domain, as is the case for NMR spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Import matplotlib style for HQS\n",
    "import HQStyle\n",
    "HQStyle.import_all()\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sine-weighted Poisson gap is a non-uniform sampling (NUS) schedule that is dense at short times. This schedule has been shown to reduce reconstruction artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-503f5456dfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mNs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoisson_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sin(alpha*pi*m/Ns)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# MY IMPLEMENTATION\n",
    "def poisson_gap(alpha, Ns): #\n",
    "    m = np.arange(1,Ns+1) #set the number of samples\n",
    "    return (1-np.sin(alpha*np.pi*m/Ns))**2 # calculate the gap with a sinusoidal function\n",
    "\n",
    "#Plot the function:\n",
    "\n",
    "alpha = 0.5\n",
    "Ns = 4096\n",
    "\n",
    "plt.plot(poisson_gap(alpha, Ns,))\n",
    "plt.xlabel('m')\n",
    "plt.ylabel('sin(alpha*pi*m/Ns)')\n",
    "plt.title('Poisson gap schedule')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The below function is generating a random distribution of points on a circle.\n",
    "#The function takes three arguments: s, p, and z.\n",
    "#s is the seed for the random number generator.\n",
    "#p is the number of points to be generated.\n",
    "#z is the number of points to be generated on the circle.\n",
    "#The function returns an array of p points on the circle.\n",
    "#The function uses the poisson function to generate a random number of points\n",
    "#between each point.\n",
    "#The function then adjusts the mean of the poisson distribution until the\n",
    "#number of points generated is equal to p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def poisson(lmbd):\n",
    "    L = np.exp(-lmbd)\n",
    "    k = 0\n",
    "    p = 1\n",
    "    while p >= L:\n",
    "        u = random.random()\n",
    "        p *= u\n",
    "        k += 1\n",
    "    return k-1\n",
    "\n",
    "def main(s, p, z):\n",
    "    ld = z/p\n",
    "    adj = 2*(ld-1)\n",
    "    random.seed(s)\n",
    "    v = np.zeros(z)\n",
    "    while True:\n",
    "        i = 0\n",
    "        n = 0\n",
    "        while i < z:\n",
    "            v[n] = i\n",
    "            i += 1\n",
    "            k = poisson(adj*np.sin((i+0.5)/(z+1)*np.pi/2))\n",
    "            i += k\n",
    "            n += 1\n",
    "        if n > p:\n",
    "            adj *= 1.02\n",
    "        if n < p:\n",
    "            adj /= 1.02\n",
    "        if n == p:\n",
    "            break\n",
    "    return v[:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 1.0\n",
    "p = 64\n",
    "z = 256\n",
    "v = main(s, p, z)\n",
    "plt.plot(v, np.zeros(len(v)), 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import linalg \n",
    "# Generate a long, sparse signal \n",
    "x = np.zeros(100000) \n",
    "x[np.random.randint(0, 100000, 1000)] = np.random.randn(1000) \n",
    "# Use compressed sensing to sample and reconstruct the signal \n",
    "y = linalg.lstsq( np.random.randn( 100000 , 1000 ), x )[ 0 ] \n",
    "x_hat = np.dot( y , np.random.randn( 1000 , 100000 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, label='x')\n",
    "plt.figure()\n",
    "plt.plot(y, label='y')\n",
    "plt.figure()\n",
    "plt.plot(x_hat, label='x_hat')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you've got the following packages installed\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as spopt\n",
    "import scipy.fftpack as spfft\n",
    "import scipy.ndimage as spimg\n",
    "import cvxpy as cvx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First what we’re going to do is create some arbitrary linear data including some noise. Let’s use the made-up equation:\n",
    "\n",
    "y=15x+3+ϵ\n",
    "\n",
    "where ϵ is some normally distributed error with standard deviation σ=0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data with noise\n",
    "x = np.sort(np.random.uniform(0, 10, 15))\n",
    "y = 3 + 0.2 * x + 0.1 * np.random.randn(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s fit two lines to the data samples. For the first line, we’ll use the L1 norm as the criterion for a good fit; for the second line, we’ll use the L2 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find L1 line fit\n",
    "l1_fit = lambda x0, x, y: np.sum(np.abs(x0[0] * x + x0[1] - y))\n",
    "xopt1 = spopt.fmin(func=l1_fit, x0=[1, 1], args=(x, y))\n",
    "\n",
    "# find L2 line fit\n",
    "l2_fit = lambda x0, x, y: np.sum(np.power(x0[0] * x + x0[1] - y, 2))\n",
    "xopt2 = spopt.fmin(func=l2_fit, x0=[1, 1], args=(x, y))\n",
    "\n",
    "plt.plot(x,y, marker='x',linestyle='None', label='Data')\n",
    "plt.plot(x,xopt1[0]*x +xopt1[1], label= 'L1')\n",
    "plt.plot(x,xopt2[0]*x +xopt2[1], label= 'L2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s get a tad crazy and add some outliers. In other words, let’s perturb a couple of the points, moving them far away from the lines. This isn’t actually all that out of the ordinary if you think about it. Outliers frequently occur in real world data, causing all kinds of headaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust data by adding outlyers\n",
    "y2 = y.copy()\n",
    "y2[3] += 4\n",
    "y2[13] -= 3\n",
    "\n",
    "# refit the lines\n",
    "xopt12 = spopt.fmin(func=l1_fit, x0=[1, 1], args=(x, y2))\n",
    "xopt22 = spopt.fmin(func=l2_fit, x0=[1, 1], args=(x, y2))\n",
    "\n",
    "plt.plot(x,y2, marker='x',linestyle='None', label='Data')\n",
    "plt.plot(x,xopt12[0]*x +xopt12[1], label= 'L1')\n",
    "plt.plot(x,xopt22[0]*x +xopt22[1], label= 'L2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction of a Simple Signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of two sinusoids\n",
    "n = 5000 # number of samples\n",
    "t = np.linspace(0, 1/8, n) # time vector\n",
    "y = np.sin(1394 * np.pi * t) + np.sin(3266 * np.pi * t) # signal\n",
    "yt = spfft.dct(y, norm='ortho') # DCT of the signal, Discrete Cosine Transform ,Fourier Transform\n",
    "\n",
    "\n",
    "plt.plot(t, y, linewidth=.2)\n",
    "plt.figure()\n",
    "plt.plot(t, yt, linewidth=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine sampling 10% of the temporal signal (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract small sample of signal\n",
    "m = 500 # 10% sample\n",
    "ri = np.random.choice(n, m, replace=False) # random sample of indices\n",
    "ri.sort() # sorting not strictly necessary, but convenient for plotting\n",
    "t2 = t[ri] #time vector resampled\n",
    "y2 = y[ri] # signal resampled\n",
    "\n",
    "# plt.plot(t2, y2, linewidth=.2)\n",
    "plt.plot(t2, y2, linewidth=.2, marker='o',linestyle='None', label='subsample')\n",
    "plt.plot(t, y, linewidth=.2,  label=' original sample')\n",
    "plt.legend()\n",
    "plt.xlim(0,0.025)\n",
    "plt.figure()\n",
    "\n",
    "print(y.shape,y2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compressed sensing in this context is made possible by the fact that the signal’s frequency content is highly sparse. This is where the L1 norm comes into play. What we want to do is, out of all possible signals, locate the simplest one that matches up with the known data. In other words, we want to use a minimization routine to find a set of frequencies satisfying two conditions: (a) the underlying signal matches up exactly (or as closely as possible) with that of our data; and (b) the L1 norm of the frequencies is minimized. Such a routine will yield a sparse solution – exactly what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there are a couple ways to accomplish this. Perhaps the easiest is to utilize the convex optimization library CVXPY. Use the code below to minimize the norm of the signal’s frequencies with the constraint that candidate signals should match up exactly with our incomplete samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create idct matrix operator in order to perform inverse DCT\n",
    "A = spfft.idct(np.identity(int(n/100)), norm='ortho', axis=0)\n",
    "#A = A[ri] # extract small sample of idct matrix, ri is the indices of the small sample\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.imshow(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# do L1 optimization\n",
    "vx = cvx.Variable(n) # variable for the coefficients\n",
    "objective = cvx.Minimize(cvx.norm(vx, 1)) # L1 norm\n",
    "constraints = [A*vx == y2] # equality constraint Ax = y , y2 is the small sample of the signal\n",
    "prob = cvx.Problem(objective, constraints) # create problem\n",
    "result = prob.solve(verbose=True) # solve problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform the minimization, we must somehow finagle our problem into a linear system of equations:\n",
    "\n",
    "Ax=b\n",
    "\n",
    "Specifically, we want to derive a matrix A that can be multiplied with a solution candidate x to yield b, a vector containing the data samples. In the context of our current problem, the candidate solution x exists in the frequency domain, while the known data b exists in the temporal domain. Clearly, the matrix A performs both a sampling and a transformation from spectral to temporal domains.\n",
    "\n",
    "Compressed sensing really comes down to being able to correctly derive the A operator. Fortunately, there’s a methodology. Start off by letting f be the target signal in vector form (if your signal is 2-dimensional or higher, flatten it) and ϕ be the sampling matrix. Then:\n",
    "\n",
    "b=ϕf\n",
    "\n",
    "Now let ψ be the matrix that transforms a signal from the spectral domain to the temporal domain. Given the solution x in the frequency domain, it follows that:\n",
    "\n",
    "ψx=f\n",
    "\n",
    "Combining the two equations yields:\n",
    "\n",
    "Ax=bwhere A≡ϕψ\n",
    "\n",
    "So, A is simply made up of rowss sampled from the domain transform matrix ψ. The ψ matrix is easy to construct – it is the inverse discrete cosine transform acting upon the columns of the identity matrix. The matrix product ψx is the equivalent to doing idct(x).\n",
    "\n",
    "Now that we’ve constructed the A matrix and run the minimization, we can reconstruct the signal by transforming the solution out of the frequency domain and back into the temporal. Below, on the left, is the original signal and its frequency content. On the right is our L1 approximation. I’d say that’s pretty good for only using 10% of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vx.value, linewidth=.2, label='reconstructed')\n",
    "plt.plot(yt, linewidth=.2 , label='original')\n",
    "plt.legend()\n",
    "plt.xlim(0,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct signal\n",
    "x = np.array(vx.value)\n",
    "x = np.squeeze(x)\n",
    "sig = spfft.idct(x, norm='ortho', axis=0)\n",
    "\n",
    "plt.plot(y, linewidth=.2, label='original signal')\n",
    "plt.plot(sig, linewidth=.2, label='reconstructed')\n",
    "plt.legend()\n",
    "plt.xlim(0,500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "280ce4e7a866954349f8aa412b867118d4f32682fc7c3afbc3d0cd1e69fe7aeb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
